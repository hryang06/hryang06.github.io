---
title: Conditionally Adaptive Multi-Task Learning 이해하기
layout: single
author_profile: true
read_time: true
comments: true
share: true
related: true
categories:
- nlp
toc: true
toc_sticky: true
toc_label: 목차
article_tag1: NLI
article_tag2: MTL
last_modified_at: 2020-10-07 15:03:00 +0800
---

[Conditionally Adaptive Multi-Task Learning: Improving Transfer Learning in NLP Using Fewer Parameters & Less Data](https://arxiv.org/abs/2009.09139) 논문 정리입니다.

## abstract

Muti-Task Learning(MTL)은 보통 다음과 같은 challenges에 대해 다뤄진다.
- ovefitting to low resource tasks
- catastrophic forgetting
- negative task transfer or learning interference

NLP에서는 MTL만으로는 일반적으로 task마다 pretrained models의 fine-tuning으로 가능한 성능에 도달하지 못했다.
하지만, 많은 fine-tuning approaches은 두 parameter 모두 inefficient하다. e.g.


