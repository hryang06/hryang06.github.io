---
title: Attention-based sequence prediction 이해하기
layout: single
author_profile: true
read_time: true
use_math: true
comments: true
share: true
related: true
categories:
- str
toc: true
toc_sticky: true
toc_label: 목차
article_tag1: STR
article_tag2: scene text recognition
article_tag3: FAN
article_tag4: focusing attention network
last_modified_at: 2020-04-28 18:07:00 +0800
---

Attention-based sequence prediction에 관한 글입니다.

[참고 논문]
- [[FAN]](https://arxiv.org/abs/1709.02054) Focusing attention: Towards accurate text recognition in natural images
- [[RARE]](https://arxiv.org/abs/1603.03915) Robust Scene Text Recognition with Automatic Rectification

## RARE

TPS-VGG-BiLSTM-Attn

### SRN : Sequence Recognition Network

- attention-based model로, input image로부터 sequence를 인식한다.
- input : rectified image(STN output), 이상적으로 문자들이 왼쪽에서 오른쪽으로 수평적 이미지
- input으로부터 sequential representation을 extract하고, 단어를 인식한다.
- SRN은 encoder와 decoder를 가진다.
    - encoder : input image로부터 sequential representation을 extract한다.
    - decoder : sequential representation에 따른 sequence를 생성한다.

![Figure 5](/assets/images/post/attn/figure5_attn.PNG)

#### 1. Encoder : Convolutional-Recurrent Network

CNN으로부터 feature map을 추출하여, map-to-sequence 연산을 통해 feature map을 여러 연속된 조각으로 분리한다.

[Figure 5]
- several convolutional layers : (input image의 robust하고 high-level의 descriptions이 포함된) feature maps 생성한다.
    - feature maps : depth D * height H * width W
- map-to-sequence operation : map의 columns를 왼쪽에서 오른쪽으로 가져와 vectors로 flatten한다.
    - sequence of W vectors : DW dimensions
    - column : local image region(receptive field)에 대응하고, 해당 region에 대한 descriptor이다.
- BLSTM : 2 layer Bidirectional Long-Short Term Memory network
    - receptive field 크기에 의해 제한되므로, feature sequence는 limited image contexts에 영향을 준다.?
    - sequence 내의 long-term dependencies를 model하기 위해서 사용한다.
    - 양방향으로 sequence 내의 dependencies를 분석할 수 있는 recurrent network
    - output은 input과 동일한 길이(L = W)의 sequence


#### 2. Decoder : Recurrent Character Generator



## FAN : Focusing Attention Network

?-ResNet-?-Attn

**기존 attention-based method 문제**
- complicated, low-quality 이미지에서 성능이 떨어짐
- cannot get accurate alignments between feature areas and targets for such images
--> **"attention drift"**

### FAN method

FAN = AN + FN

![Figure 2](/assets/images/post/attn/figure2.png)

![Figure 5](/assets/images/post/attn/figure5_fan.PNG)

#### AN : Attention Network

recognizing character targets (기존 방법처럼)

#### FN : Focusing Network

adjusting attention by evaluating whether AN pays attention properly on the target areas in the images

#### FAN training

#### decoding
