---
title: Heuristic Analysis for NLI systems
layout: single
classes: wide
author_profile: true
read_time: true
comments: true
share: true
related: true
categories:
- nlp
toc: true
toc_sticky: true
toc_label: 목차
article_tag1: NLP
article_tag2: BERT
last_modified_at: 2020-09-09 15:03:00 +0800
---

# HANS : Heuristics Analysis fo Natural language inference Systems

[Right for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural Language Inference](https://arxiv.org/abs/1902.01007) 논문을 정리한 글입니다.

github : <https://github.com/tommccoy1/hans>

## paper

### abstract

MNLI에서 학습한 BERT 모델의 경우 HANS에서 매우 낮은 성능을 보이는 것을 발견하였다. 본 논문에서는 NLI system을 개선할 수 있는 상당한 여지가 있으며, HANS dataset가 이러한 영역에서 동기를 부여하며 측정할 수 있다고 이야기한다.

### contributions

1. HANS dataset : NLI 모델이 학습할 가능성이 높은 잘못된 heuristics에 대한 특정 가설을 테스트하는 NLI evaluation set

2. MNLI에서 훈련된 state-of-the-art models의 interpretable shortcomings를 밝히기 위해 HANS dataset 사용 : 이러한 단점은 아래에서 발생할 수 있다.
    - inappropriate model inductive biases
    - insufficient signal by training datasets
    - or both

3. 이러한 단점들이 HANS에 존재하는 사례의 종류로 training set을 augmentation함으로써 이러한 단점들이 덜해지는 것을 보여준다.

### conclusions

기존의 네 가지 NLI 모델이 HANS에서 매우 저조한 성능을 보인다는 것을 발견했는데, 이는 NLI test set의 높은 정확도가 언어에 대한 깊은 이해보다는 잘못된 heuristics 이용 때문이라는 것을 시사한다.

standard evaluations에 대한 state-of-the-art models의 인상적인 정확성에도 불구하고 여전히 많은 진전이 이뤄져야 하며, HANS와 같이 chellenging dataset가 모델이 배우고자 하는 것을 배우는지를 결정하는 데 중요하다는 것을 보여준다.

## Natural Language Inference(NLI) system

NLI는 premise(A)에 대해 hypothesis(B)가 true(entailment)인지, false(contradiction)인지, undetermined(neutral)인지 판단한다.

## syntatic heuristics

![Heuristics taget](/assets/images/post/hans/hans-heuristics-target.PNG)

- hierarchy : constituent heuristic < subsequence heuristic < lexical overlap heuristic

- standard NLI training datasets(SNLI, MNLI)에 대해 train하는 statistical learner가 heuristics를 채택할 두가지 이유
    1. MNLI training set에는 heuristics에 해당하는 examples이 아닌 것보다 더 많이 포함되어 있다.
    2. input representations가 heuristics에 취약하게 만들 수 있다.

![Heuristics Examples](/assets/images/post/hans/heuristics-examples.PNG)

### 1) lexical overlap heuristic

### 2) subsequence heuristic

### 3) constituent heuristic


# AFLITE : Lightweight Adversarial Filtering

[Adversarial Filters of Dataset Biases](https://arxiv.org/abs/2002.04108) 논문을 정리한 글입니다.

![AFLITE acc](/assets/images/post/hans/aflite-acc.PNG)

![AFLITE SNLI](/assets/images/post/hans/snli-aflite.PNG)

## AFLITE algorithm

![AFLITE algorithm](/assets/images/post/hans/aflite-algorithm.PNG)
